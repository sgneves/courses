{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a spam filter with Naive Bayes\n",
    "\n",
    "This project aims to build a spam filter for SMS messages using the [multinomial Naive Bayes algorithm]( https://en.wikipedia.org/wiki/Naive_Bayes_classifier#Multinomial_na%C3%AFve_Bayes). We will use a dataset put together by Tiago A. Almeida and José María Gómez Hidalgo. The dataset can be downloaded from the [The UCI Machine Learning Repository]( https://archive.ics.uci.edu/ml/datasets/sms+spam+collection). The data collection process is described in more detail on [this page]( http://www.dt.fee.unicamp.br/~tiago/smsspamcollection/#composition), where you can also find some of the authors' papers. The spam filter needs to classify new messages with an accuracy greater than 80%.\n",
    "\n",
    "## Overview of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modules\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4456</th>\n",
       "      <td>ham</td>\n",
       "      <td>Storming msg: Wen u lift d phne, u say \"HELLO\"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>690</th>\n",
       "      <td>spam</td>\n",
       "      <td>&lt;Forwarded from 448712404000&gt;Please CALL 08712...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>944</th>\n",
       "      <td>ham</td>\n",
       "      <td>And also I've sorta blown him off a couple tim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3768</th>\n",
       "      <td>ham</td>\n",
       "      <td>Sir Goodmorning, Once free call me.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1189</th>\n",
       "      <td>ham</td>\n",
       "      <td>All will come alive.better correct any good lo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4437</th>\n",
       "      <td>ham</td>\n",
       "      <td>House-Maid is the murderer, coz the man was mu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3587</th>\n",
       "      <td>spam</td>\n",
       "      <td>I am hot n horny and willing I live local to y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1982</th>\n",
       "      <td>ham</td>\n",
       "      <td>Sorry, I'll call later in meeting any thing re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2038</th>\n",
       "      <td>ham</td>\n",
       "      <td>Oh sorry please its over</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2078</th>\n",
       "      <td>ham</td>\n",
       "      <td>Hey hun-onbus goin 2 meet him. He wants 2go ou...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Label                                                SMS\n",
       "4456   ham  Storming msg: Wen u lift d phne, u say \"HELLO\"...\n",
       "690   spam  <Forwarded from 448712404000>Please CALL 08712...\n",
       "944    ham  And also I've sorta blown him off a couple tim...\n",
       "3768   ham                Sir Goodmorning, Once free call me.\n",
       "1189   ham  All will come alive.better correct any good lo...\n",
       "4437   ham  House-Maid is the murderer, coz the man was mu...\n",
       "3587  spam  I am hot n horny and willing I live local to y...\n",
       "1982   ham  Sorry, I'll call later in meeting any thing re...\n",
       "2038   ham                           Oh sorry please its over\n",
       "2078   ham  Hey hun-onbus goin 2 meet him. He wants 2go ou..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the dataset\n",
    "labelled_sms = pd.read_csv('SMSSpamCollection', sep='\\t', header=None, names=['Label', 'SMS'])\n",
    "labelled_sms.sample(10, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This dataset has 5572 rows.\n"
     ]
    }
   ],
   "source": [
    "print(\"This dataset has {} rows.\".format(labelled_sms.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ham     86.593683\n",
       "spam    13.406317\n",
       "Name: Label, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labelled_sms[\"Label\"].value_counts(normalize=True) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The label `ham` means not-spam. The dataset contains 13.4% of spam messages.\n",
    "\n",
    "## Data cleaning\n",
    "\n",
    "The spam algorithm we are developing will not account for the punctuation. We will remove all non-alphanumeric characters. The algorithm will also interpret upper and lowercase letters as being the same. We will transform all letters to lowercase.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4456</th>\n",
       "      <td>ham</td>\n",
       "      <td>[storming, msg, wen, u, lift, d, phne, u, say,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>690</th>\n",
       "      <td>spam</td>\n",
       "      <td>[forwarded, from, 448712404000, please, call, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>944</th>\n",
       "      <td>ham</td>\n",
       "      <td>[and, also, i, ve, sorta, blown, him, off, a, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3768</th>\n",
       "      <td>ham</td>\n",
       "      <td>[sir, goodmorning, once, free, call, me]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1189</th>\n",
       "      <td>ham</td>\n",
       "      <td>[all, will, come, alive, better, correct, any,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4437</th>\n",
       "      <td>ham</td>\n",
       "      <td>[house, maid, is, the, murderer, coz, the, man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3587</th>\n",
       "      <td>spam</td>\n",
       "      <td>[i, am, hot, n, horny, and, willing, i, live, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1982</th>\n",
       "      <td>ham</td>\n",
       "      <td>[sorry, i, ll, call, later, in, meeting, any, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2038</th>\n",
       "      <td>ham</td>\n",
       "      <td>[oh, sorry, please, its, over]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2078</th>\n",
       "      <td>ham</td>\n",
       "      <td>[hey, hun, onbus, goin, 2, meet, him, he, want...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Label                                                SMS\n",
       "4456   ham  [storming, msg, wen, u, lift, d, phne, u, say,...\n",
       "690   spam  [forwarded, from, 448712404000, please, call, ...\n",
       "944    ham  [and, also, i, ve, sorta, blown, him, off, a, ...\n",
       "3768   ham           [sir, goodmorning, once, free, call, me]\n",
       "1189   ham  [all, will, come, alive, better, correct, any,...\n",
       "4437   ham  [house, maid, is, the, murderer, coz, the, man...\n",
       "3587  spam  [i, am, hot, n, horny, and, willing, i, live, ...\n",
       "1982   ham  [sorry, i, ll, call, later, in, meeting, any, ...\n",
       "2038   ham                     [oh, sorry, please, its, over]\n",
       "2078   ham  [hey, hun, onbus, goin, 2, meet, him, he, want..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labelled_sms[\"SMS\"] = labelled_sms[\"SMS\"].str.replace(r\"\\W\", \" \").str.lower().str.split()\n",
    "labelled_sms.sample(10, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and test sets\n",
    "\n",
    "To test the spam filter, we will split our dataset into two categories:\n",
    "\n",
    "* Training set - used to train the algorithm on how to classify messages. This set will have 4,458 messages (about 80% of the dataset).\n",
    "* Test set -  Used to test how good the spam filter is for classifying new messages. This set will have 1,114 messages (about 20% of the dataset)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set has 13.5% of spam emails.\n",
      "Test set has 13.2% of spam emails.\n"
     ]
    }
   ],
   "source": [
    "# Randomize the order of the dataset\n",
    "labelled_sms = labelled_sms.sample(frac=1, random_state=1)\n",
    "\n",
    "# Split into training and test sets\n",
    "training_set = labelled_sms[:4458].reset_index(drop=True)\n",
    "test_set = labelled_sms[-1114:].reset_index(drop=True)\n",
    "\n",
    "# Check the percentages of spam emails on both sets\n",
    "print(\"Training set has {:.1f}% of spam emails.\".format(training_set[\"Label\"].value_counts(normalize=True)[\"spam\"] * 100))\n",
    "print(\"Test set has {:.1f}% of spam emails.\".format(test_set[\"Label\"].value_counts(normalize=True)[\"spam\"] * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The percentage of spam emails on both subsets are similar to that of the original set.\n",
    "\n",
    "## Vocabulary and word count\n",
    "\n",
    "Now we will create a list with all the unique words that occur in the messages of our training set. After, we will count the number of times that each unique word appears in each message."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary has 7783 unique words.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "      <th>desparate</th>\n",
       "      <th>inde</th>\n",
       "      <th>feathery</th>\n",
       "      <th>messed</th>\n",
       "      <th>545</th>\n",
       "      <th>archive</th>\n",
       "      <th>happier</th>\n",
       "      <th>rearrange</th>\n",
       "      <th>...</th>\n",
       "      <th>heltini</th>\n",
       "      <th>planning</th>\n",
       "      <th>choose</th>\n",
       "      <th>24th</th>\n",
       "      <th>tightly</th>\n",
       "      <th>wicket</th>\n",
       "      <th>bash</th>\n",
       "      <th>watevr</th>\n",
       "      <th>word</th>\n",
       "      <th>creep</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>[yep, by, the, pretty, sculpture]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>[yes, princess, are, you, going, to, make, me,...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>[welp, apparently, he, retired]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>[havent]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>[i, forgot, 2, ask, ü, all, smth, there, s, a,...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 7785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                                SMS  desparate  inde  \\\n",
       "0   ham                  [yep, by, the, pretty, sculpture]          0     0   \n",
       "1   ham  [yes, princess, are, you, going, to, make, me,...          0     0   \n",
       "2   ham                    [welp, apparently, he, retired]          0     0   \n",
       "3   ham                                           [havent]          0     0   \n",
       "4   ham  [i, forgot, 2, ask, ü, all, smth, there, s, a,...          0     0   \n",
       "\n",
       "   feathery  messed  545  archive  happier  rearrange  ...  heltini  planning  \\\n",
       "0         0       0    0        0        0          0  ...        0         0   \n",
       "1         0       0    0        0        0          0  ...        0         0   \n",
       "2         0       0    0        0        0          0  ...        0         0   \n",
       "3         0       0    0        0        0          0  ...        0         0   \n",
       "4         0       0    0        0        0          0  ...        0         0   \n",
       "\n",
       "   choose  24th  tightly  wicket  bash  watevr  word  creep  \n",
       "0       0     0        0       0     0       0     0      0  \n",
       "1       0     0        0       0     0       0     0      0  \n",
       "2       0     0        0       0     0       0     0      0  \n",
       "3       0     0        0       0     0       0     0      0  \n",
       "4       0     0        0       0     0       0     0      0  \n",
       "\n",
       "[5 rows x 7785 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List with all the unique words\n",
    "vocabulary = list(set([j for i in training_set[\"SMS\"] for j in i]))\n",
    "\n",
    "print(\"Vocabulary has {} unique words.\".format(len(vocabulary)))\n",
    "\n",
    "# Count the number of times that each unique word appears in each message\n",
    "word_count = {word: [0] * len(training_set[\"SMS\"]) for word in vocabulary}\n",
    "\n",
    "for index, sms in enumerate(training_set[\"SMS\"]):\n",
    "\n",
    "    for word in sms:\n",
    "       \n",
    "        word_count[word][index] += 1\n",
    "\n",
    "# Transform word_count into a DataFrame \n",
    "word_count = pd.DataFrame(word_count)\n",
    "\n",
    "# Concatenate our training set with our word count\n",
    "training_set = pd.concat([training_set, word_count], axis=1)\n",
    "training_set.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize data\n",
    "\n",
    "The Naive Bayes algorithm that we will implement in our spam filter uses the following equations:\n",
    "\n",
    "\\begin{equation}\n",
    "P(Spam | w_1,w_2, ..., w_n) \\propto P(Spam) \\cdot \\prod_{i=1}^{n}P(w_i|Spam)\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "P(Ham | w_1,w_2, ..., w_n) \\propto P(Ham) \\cdot \\prod_{i=1}^{n}P(w_i|Ham)\n",
    "\\end{equation}\n",
    "\n",
    "where\n",
    "\n",
    "\\begin{equation}\n",
    "P(w_i|Spam) = \\frac{N_{w_i|Spam} + \\alpha}{N_{Spam} + \\alpha \\cdot N_{Vocabulary}}\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "P(w_i|Ham) = \\frac{N_{w_i|Ham} + \\alpha}{N_{Ham} + \\alpha \\cdot N_{Vocabulary}}\n",
    "\\end{equation}\n",
    "\n",
    "We will use Laplace smoothing $\\alpha = 1$ and will start by calculating the constant terms of these equations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p_spam = 0.135\n",
      "p_ham = 0.865\n",
      "n_spam = 15190\n",
      "n_ham = 57237\n",
      "n_vocab = 7783\n"
     ]
    }
   ],
   "source": [
    "alpha = 1\n",
    "\n",
    "is_spam = training_set[\"Label\"] == \"spam\"\n",
    "p_spam = (is_spam).sum() / training_set.shape[0]\n",
    "print(\"p_spam = {:.3f}\".format(p_spam))\n",
    "\n",
    "p_ham = 1 - p_spam\n",
    "print(\"p_ham = {:.3f}\".format(p_ham))\n",
    "\n",
    "n_spam = training_set.iloc[is_spam.values,2:].to_numpy().sum()\n",
    "print(\"n_spam = {}\".format(n_spam))\n",
    "\n",
    "n_ham = training_set.iloc[~is_spam.values,2:].to_numpy().sum()\n",
    "print(\"n_ham = {}\".format(n_ham))\n",
    "\n",
    "n_vocab = len(vocabulary)\n",
    "print(\"n_vocab = {}\".format(n_vocab))\n",
    "\n",
    "p_wi_given_spam = {word: (training_set.loc[is_spam,word].sum() + alpha) / (n_spam + alpha * n_vocab) for word in vocabulary}\n",
    "\n",
    "p_wi_given_ham = {word: (training_set.loc[~is_spam,word].sum() + alpha) / (n_ham + alpha * n_vocab) for word in vocabulary}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If $wi$ it is a new word, the parameters $P(w_i|Spam)$ and $P(w_i|Ham) become:\n",
    "\n",
    "\\begin{equation}\n",
    "P(w_i|Spam) = \\frac{\\alpha}{N_{Spam} + \\alpha \\cdot N_{Vocabulary}}\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "P(w_i|Ham) = \\frac{\\alpha}{N_{Ham} + \\alpha \\cdot N_{Vocabulary}}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p_new_wi_given_spam = 4.353E-05\n",
      "p_new_wi_given_ham = 1.538E-05\n"
     ]
    }
   ],
   "source": [
    "p_new_wi_given_spam = alpha / (n_spam + alpha * n_vocab)\n",
    "print(\"p_new_wi_given_spam = {:.3E}\".format(p_new_wi_given_spam))\n",
    "\n",
    "p_new_wi_given_ham = alpha / (n_ham + alpha * n_vocab)\n",
    "print(\"p_new_wi_given_ham = {:.3E}\".format(p_new_wi_given_ham))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00021764680276846734\n",
      "0.0006920947400799754\n"
     ]
    }
   ],
   "source": [
    "word = \"money\"\n",
    "print(p_wi_given_spam[word])\n",
    "print(p_wi_given_ham[word])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifying a new message\n",
    "\n",
    "Now that we've initialized all the data, we can start creating the spam filter. The spam filter can be understood as a function that:\n",
    "\n",
    "* Takes in as input a new message (w<sub>1</sub>, w<sub>2</sub>, ..., w<sub>n</sub>).\n",
    "* Calculates P(Spam|w<sub>1</sub>, w<sub>2</sub>, ..., w<sub>n</sub>) and P(Ham|w<sub>1</sub>, w<sub>2</sub>, ..., w<sub>n</sub>).\n",
    "* Compares the values of P(Spam|w<sub>1</sub>, w<sub>2</sub>, ..., w<sub>n</sub>) and P(Ham|w<sub>1</sub>, w<sub>2</sub>, ..., w<sub>n</sub>), and:\n",
    "  * If P(Ham|w<sub>1</sub>, w<sub>2</sub>, ..., w<sub>n</sub>) > P(Spam|w<sub>1</sub>, w<sub>2</sub>, ..., w<sub>n</sub>), then the message is classified as ham.\n",
    "  * If P(Ham|w<sub>1</sub>, w<sub>2</sub>, ..., w<sub>n</sub>) < P(Spam|w<sub>1</sub>, w<sub>2</sub>, ..., w<sub>n</sub>), then the message is classified as spam.\n",
    "  * If P(Ham|w<sub>1</sub>, w<sub>2</sub>, ..., w<sub>n</sub>) = P(Spam|w<sub>1</sub>, w<sub>2</sub>, ..., w<sub>n</sub>), then the algorithm may request human help."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(sms):\n",
    "\n",
    "    # Check if it is a string\n",
    "    if type(sms) == str: sms = re.sub('\\W', ' ', sms).lower().split()\n",
    "    \n",
    "    # Calculate p_spam_given_sms and p_ham_given_sms\n",
    "    p_spam_given_sms = p_spam * np.prod([p_wi_given_spam[word] if word in p_wi_given_spam else 1 for word in sms])\n",
    "    p_ham_given_sms = p_ham * np.prod([p_wi_given_ham[word] if word in p_wi_given_ham else 1 for word in sms])\n",
    "\n",
    "    # Classify the message\n",
    "    if p_ham_given_sms > p_spam_given_sms:\n",
    "        label = \"ham\"\n",
    "    elif p_ham_given_sms < p_spam_given_sms:\n",
    "        label = \"spam\"\n",
    "    else:\n",
    "        label = \"unclassified\"\n",
    "        \n",
    "    return label, p_spam_given_sms, p_ham_given_sms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: spam\n",
      "P(Spam|sms): 1.3481290211300841e-25\n",
      "P(Ham|sms): 1.936804902858988e-27\n"
     ]
    }
   ],
   "source": [
    "label, p_spam_given_sms, p_ham_given_sms = classify(\"WINNER!! This is the secret code to unlock the money: C3421.\")\n",
    "print('Label:', label)\n",
    "print('P(Spam|sms):', p_spam_given_sms)\n",
    "print('P(Ham|sms):', p_ham_given_sms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: ham\n",
      "P(Spam|sms): 2.4372375665888113e-25\n",
      "P(Ham|sms): 3.687530435009238e-21\n"
     ]
    }
   ],
   "source": [
    "label, p_spam_given_sms, p_ham_given_sms = classify(\"Sounds good, Tom, then see u there\")\n",
    "print('Label:', label)\n",
    "print('P(Spam|sms):', p_spam_given_sms)\n",
    "print('P(Ham|sms):', p_ham_given_sms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measuring the spam filter's accuracy\n",
    "\n",
    "We'll now try to determine the accuracy of the spam filter using our test set of 1,114 messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>[later, i, guess, i, needa, do, mcat, study, too]</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>[but, i, haf, enuff, space, got, like, 4, mb]</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>[had, your, mobile, 10, mths, update, to, late...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>[all, sounds, good, fingers, makes, it, diffic...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>[all, done, all, handed, in, don, t, know, if,...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                                SMS predicted\n",
       "0   ham  [later, i, guess, i, needa, do, mcat, study, too]       ham\n",
       "1   ham      [but, i, haf, enuff, space, got, like, 4, mb]       ham\n",
       "2  spam  [had, your, mobile, 10, mths, update, to, late...      spam\n",
       "3   ham  [all, sounds, good, fingers, makes, it, diffic...       ham\n",
       "4   ham  [all, done, all, handed, in, don, t, know, if,...       ham"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set['predicted'] = test_set['SMS'].apply(lambda x: classify(x)[0])\n",
    "test_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Spam accuracy: 98.7%'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"Spam accuracy: {:.1f}%\".format((test_set['Label'] == test_set['predicted']).sum() / test_set.shape[0] * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions and further developments\n",
    "\n",
    "We managed to build a spam filter for SMS messages using the multinomial Naive Bayes algorithm. The filter had an accuracy of 98.74% on the test set, which is an excellent result. We initially aimed for an accuracy of over 80%.\n",
    "In terms of further developments, we could isolate the 14 messages that were classified incorrectly and try to figure out why the algorithm reached the wrong conclusions. Also, we might be able to increase the accuracy of the filtering process by accounting for letter case and punctuation."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
